{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Battle of the Neighborhoods\n\n## 1. Introduction\n\nIn this project I will focus on the neighborhoods in London. The question under consideration is, what is the best area in London to open a new restaurant? On a related note, I will try to find the best place to open a cafe. The insights that I will obtain in the process can help future business owners to find promising spots for their planned establishment. Among other things, I will take into consideration the current distribution of cafes/restaurants in the various neighborhoods and (if possible) the population density.\n\n## 2. Data Description\n\nThe first step is to obtain the names and locations of London's neighborhoods. This will be realized by importing a comprehensive list from https://en.wikipedia.org/wiki/List_of_areas_of_London, where names of all areas in London can be found. Each entry of this table has an attribute referring to a webpage like https://geohack.toolforge.org/geohack.php?pagename=List_of_areas_of_London&params=51.48648031512_N_0.10859224316653_E_region:GB_scale:25000, where the geographical position can be determined. Once I have constructed a table with neighborhood names and locations, I will use the Foursquare database to explore each area individually. Attributes I will focus on are density of restaurants, density of cafes and population (i.e. potential customer) density. In addition I will perform a clustering algorithm in order to identify high-density regions more easily."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nfrom urllib.request import urlopen\nfrom xml.etree.ElementTree import parse\nimport bs4 as bs\nimport numpy as np",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# wikipedia page containing areas in London\npath_wiki = 'https://en.wikipedia.org/wiki/List_of_areas_of_London'\n\n# read web-page\nfull_wiki_df = pd.read_html(path_wiki)\n\n# extract the relevant table\ndf = full_wiki_df[1]\n\nprint('Initial table has shape ' + str(df.shape))\ndf.head()",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Initial table has shape (533, 6)\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 2,
                    "data": {
                        "text/plain": "      Location                     London\u00a0borough       Post town  \\\n0   Abbey Wood              Bexley, Greenwich [7]          LONDON   \n1        Acton  Ealing, Hammersmith and Fulham[8]          LONDON   \n2    Addington                         Croydon[8]         CROYDON   \n3   Addiscombe                         Croydon[8]         CROYDON   \n4  Albany Park                             Bexley  BEXLEY, SIDCUP   \n\n  Postcode\u00a0district Dial\u00a0code OS grid ref  \n0               SE2       020    TQ465785  \n1            W3, W4       020    TQ205805  \n2               CR0       020    TQ375645  \n3               CR0       020    TQ345665  \n4         DA5, DA14       020    TQ478728  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Location</th>\n      <th>London\u00a0borough</th>\n      <th>Post town</th>\n      <th>Postcode\u00a0district</th>\n      <th>Dial\u00a0code</th>\n      <th>OS grid ref</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abbey Wood</td>\n      <td>Bexley, Greenwich [7]</td>\n      <td>LONDON</td>\n      <td>SE2</td>\n      <td>020</td>\n      <td>TQ465785</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Acton</td>\n      <td>Ealing, Hammersmith and Fulham[8]</td>\n      <td>LONDON</td>\n      <td>W3, W4</td>\n      <td>020</td>\n      <td>TQ205805</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Addington</td>\n      <td>Croydon[8]</td>\n      <td>CROYDON</td>\n      <td>CR0</td>\n      <td>020</td>\n      <td>TQ375645</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Addiscombe</td>\n      <td>Croydon[8]</td>\n      <td>CROYDON</td>\n      <td>CR0</td>\n      <td>020</td>\n      <td>TQ345665</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albany Park</td>\n      <td>Bexley</td>\n      <td>BEXLEY, SIDCUP</td>\n      <td>DA5, DA14</td>\n      <td>020</td>\n      <td>TQ478728</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def read_wiki_page(url):\n  \n    identifier = 'List of places UK England London'\n\n    # extract first entry directly\n    temp_df = pd.read_html(url)\n\n    # check if there's a box on top\n    if temp_df[0].shape==(1,2):\n        temp_df = temp_df[1]\n    else:\n        temp_df = temp_df[0]\n        \n    # get column names\n    temp_columns = temp_df.columns.tolist()\n        \n    contains_coord = False\n        \n    # go through the rows\n    for row in range(0,len(temp_df)):\n\n        if identifier in str(temp_df.iloc[[row][co]][1]):\n            contains_coord = True\n            print('    Coordinates readable')\n            break\n            \n    if not contains_coord:\n        raise Exception('url not valid')\n        \n    ",
            "execution_count": 125,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wikipedia = 'https://en.wikipedia.org/wiki/'\nidentifier = 'List of places UK England London'\n\nlist_neighborhoods = []\nlist_coordinates = []\n\nfor row in range(0,3):#len(df)):\n    \n    # get location string of current row\n    curr_loc = df.iloc[row]['Location']\n    \n    # some entries have an alternative name written like 'name (alternative name)' -> remove the brackets+content\n    split_by_bracket = str.split(curr_loc,' (')\n    loc_no_bracket = split_by_bracket[0]\n    \n    # replace white spaces between words by _\n    no_spaces = loc_no_bracket.replace(' ','_')\n    \n    # ignore every occurence of '\n    no_dash = no_spaces.replace(\"'\",\"\")\n    \n    # contruct possible url\n    url_guess = wikipedia + no_dash\n    \n    print(url_guess)\n    \n    try:\n        read_wiki_page(url_guess)                \n    except:\n        \n        print('    Address not valid, try alternative')\n        \n        # if the url has not been correct so far, add ',_London' to construct a second guess\n        url_guess = url_guess + ',_London'\n        print('    ' + url_guess)\n        \n        try:\n            read_wiki_page(url_guess)\n        except:\n                print('    Alternative address also not valid, discard entry')\n                continue",
            "execution_count": 126,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "https://en.wikipedia.org/wiki/Abbey_Wood\n    Coordinates readable\nhttps://en.wikipedia.org/wiki/Acton\n    Address not valid, try alternative\n    https://en.wikipedia.org/wiki/Acton,_London\n    Coordinates readable\nhttps://en.wikipedia.org/wiki/Addington\n    Address not valid, try alternative\n    https://en.wikipedia.org/wiki/Addington,_London\n    Coordinates readable\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "temp_df.shape == (1,2)",
            "execution_count": 118,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 118,
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": ""
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def parse_XML(xml_file, df_cols): \n    \"\"\"Parse the input XML file and store the result in a pandas \n    DataFrame with the given columns. \n    \n    The first element of df_cols is supposed to be the identifier \n    variable, which is an attribute of each node element in the \n    XML data; other features will be parsed from the text content \n    of each sub-element. \n    \"\"\"\n    \n    xtree = et.parse(xml_file)\n    xroot = xtree.getroot()\n    rows = []\n    \n    for node in xroot: \n        res = []\n        res.append(node.attrib.get(df_cols[0]))\n        for el in df_cols[1:]: \n            if node is not None and node.find(el) is not None:\n                res.append(node.find(el).text)\n            else: \n                res.append(None)\n        rows.append({df_cols[i]: res[i] \n                     for i, _ in enumerate(df_cols)})\n    \n    out_df = pd.DataFrame(rows, columns=df_cols)\n        \n    return out_df\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_5e07c498d6f54713b4afa36144761a42 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='38IB3Xg3UtbCba8gta1-seldj8LjcSCq85MseQOEj-KU',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1 = client_5e07c498d6f54713b4afa36144761a42.get_object(Bucket='courseracapstoneproject-donotdelete-pr-mvaxyenlgvfj8y', Key='doc.kml')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}